# ğŸ”¥ CRINGE RPG-AI Multi-Bot Backend - VersÃ£o 1.0

Este projeto Ã© um backend de alto desempenho, construÃ­do com **FastAPI** e **Python**, desenhado para gerenciar um jogo de RPG de mesa onde mÃºltiplos personagens e o Mestre do Jogo sÃ£o controlados por Agentes de InteligÃªncia Artificial (Gemini API).

O nome oficial do projeto Ã© **CRINGE**.

A **VersÃ£o 1.0** estabelece a arquitetura completa de dados e as rotas de API para gerenciar usuÃ¡rios, bots, grupos de chat e o histÃ³rico de mensagens.

## ğŸš€ Status da VersÃ£o 1.0

âœ… **Arquitetura Base:** Completa.
âœ… **Modelos de Dados (Pydantic):** Finalizados (`User`, `Bot`, `ChatGroup`, `Message`).
âœ… **SimulaÃ§Ã£o de Banco de Dados:** Funcional (`db.py`).
âœ… **Rotas FastAPI:** Criadas e testadas.
ğŸ›‘ **LÃ³gica de IA:** SimulaÃ§Ã£o (Hardcoded) na rota `/groups/send_message`.

---

## ğŸ› ï¸ Detalhes da Tecnologia

* **Framework:** FastAPI (Python)
* **Servidor:** Uvicorn (ASGI)
* **Gerenciamento de Ambiente:** Conda (`rpg-ia`)
* **Modelo de IA Integrado (Futuro):** Google Gemini API (`google-genai`)

## ğŸ“‚ Estrutura do Projeto

/cringe/1.0/
â”œâ”€â”€ main.py        # AplicaÃ§Ã£o FastAPI, define as rotas da API.
â”œâ”€â”€ db.py          # SimulaÃ§Ã£o de Banco de Dados em memÃ³ria (inicializa dados para teste).
â”œâ”€â”€ models.py      # DefiniÃ§Ã£o dos modelos de dados (classes Pydantic).
â”œâ”€â”€ requirements.txt # Lista de dependÃªncias Python.
â””â”€â”€ README.md      # Este arquivo.


## âš™ï¸ ConfiguraÃ§Ã£o e InicializaÃ§Ã£o

O projeto deve ser rodado dentro do ambiente Conda chamado `rpg-ia`.

### 1. Instalar DependÃªncias

Certifique-se de estar na pasta `C:\cringe\1.0` e com o ambiente `(rpg-ia)` ativo:

```bash
pip install -r requirements.txt
2. Rodar o Servidor
O servidor Uvicorn deve ser iniciado usando a porta 8080 (para evitar bloqueios de firewall). O flag --reload garante que o servidor reinicie automaticamente apÃ³s salvar alteraÃ§Ãµes no cÃ³digo.

Bash

uvicorn main:app --reload --port 8080
3. Acessar a DocumentaÃ§Ã£o da API
Com o servidor rodando, a documentaÃ§Ã£o interativa (Swagger UI) estÃ¡ acessÃ­vel em:

http://127.0.0.1:8080/docs

ğŸ§­ Rotas Principais da API
As rotas jÃ¡ estÃ£o configuradas para interagir com os dados simulados:

MÃ©todo	Endpoint	DescriÃ§Ã£o	Modelo de Input
GET	/	Confirma o status da API.	N/A
GET	/groups/{group_id}	Retorna o estado completo de um grupo de chat (inclui histÃ³rico).	group-123 (ID de teste)
GET	/users/{user_id}	Retorna detalhes de um usuÃ¡rio.	user-1 (ID de teste)
POST	/groups/send_message	Recebe mensagem do usuÃ¡rio, salva, e aciona a IA.	NewMessage (JSON)
ğŸŒŸ PrÃ³xima Fase: IntegraÃ§Ã£o e LÃ³gica da IA
A rota POST /groups/send_message atualmente contÃ©m uma resposta simulada. O objetivo da prÃ³xima fase Ã©:

Configurar a autenticaÃ§Ã£o do Gemini API (GEMINI_API_KEY).

Implementar a lÃ³gica no main.py para iterar sobre os bots do grupo (bot-mestre, bot-npc-1).

Para cada bot, montar um prompt de sistema/histÃ³rico de chat.

Chamar o modelo gemini-2.5-flash de forma assÃ­ncrona para gerar as respostas.

Salvar as respostas geradas pelos bots no histÃ³rico do grupo (db.py).