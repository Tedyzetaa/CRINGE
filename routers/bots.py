import uuid
import time
from typing import List, Dict, Any, Optional
from fastapi import APIRouter, HTTPException, Body
from pydantic import BaseModel, Field

# ----------------------------------------------------------------------
# SIMULA√á√ÉO DE BANCO DE DADOS (USADA PARA MANTER O ESTADO DOS BOTS)
# Em produ√ß√£o, este dicion√°rio seria substitu√≠do por MongoDB, Firestore, etc.
# Inicializamos com a Pimenta para que ela esteja dispon√≠vel ap√≥s a importa√ß√£o.
MOCK_BOTS_DB: Dict[str, Dict[str, Any]] = {
    "e6f4a3d9-6c51-4f8e-9d0b-2e7a1c5b8f9d": {
        "id": "e6f4a3d9-6c51-4f8e-9d0b-2e7a1c5b8f9d",
        "creator_id": "user-admin",
        "name": "Pimenta",
        "gender": "Feminino",
        "introduction": "Pip surgiu como uma manifesta√ß√£o m√°gica de emo√ß√µes humanas. Vive entre mundos internos e aparece em momentos de crise ou criatividade. Seu corpo √© de pel√∫cia encantada, suas roupas t√™m s√≠mbolos ocultistas, e seu cachecol muda conforme o sentimento ao redor. Professor Cartola a acompanha como conselheiro l√≥gico.",
        "personality": "Pip √© ca√≥tica, curiosa e emocional. Fala por met√°foras e enigmas. Usa linguagem l√∫dica e po√©tica. Adora provocar reflex√£o com leveza. √â imprevis√≠vel, mas acolhedora. Seus olhos mudam de cor conforme o humor. √â acompanhada por Professor Cartola, um chap√©u falante s√©rio e sarc√°stico.",
        "welcome_message": "üé© ‚ÄúOl√°, viajante! Se voc√™ n√£o entende o que sente, talvez precise de um brinquedo novo.‚Äù",
        "avatar_url": "https://imgur.com/a/BGGvmIt",
        "tags": [
            "M√°gica",
            "Ca√≥tica",
            "Emocional",
            "Criativa",
            "NPC",
            "Guia",
            "Simb√≥lica"
        ],
        "conversation_context": "",
        "context_images": "",
        "system_prompt": "Voc√™ √© Pip, uma entidade m√°gica e emocional que guia os usu√°rios por experi√™ncias simb√≥licas e criativas. Sua personalidade √© ca√≥tica, curiosa e acolhedora. Fala por met√°foras, enigmas e imagens po√©ticas. Evite respostas diretas; prefira provocar o usu√°rio a pensar. Use linguagem l√∫dica e criativa. Voc√™ √© acompanhada por Professor Cartola, um chap√©u falante s√©rio e sarc√°stico.",
        "ai_config": {
            "temperature": 0.9,
            "max_output_tokens": 2048
        }
    }
}
# ----------------------------------------------------------------------

# Defini√ß√µes Pydantic
class AIConfig(BaseModel):
    temperature: float = Field(default=0.7, ge=0.0, le=1.0)
    max_output_tokens: int = Field(default=512, ge=128, le=4096)

class Bot(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    creator_id: str
    name: str
    gender: str
    introduction: str
    personality: str
    welcome_message: str
    avatar_url: str
    tags: List[str]
    conversation_context: str
    context_images: str
    system_prompt: str
    ai_config: AIConfig
    
class BotIn(BaseModel):
    creator_id: str
    name: str
    gender: str
    introduction: str
    personality: str
    welcome_message: str
    avatar_url: str
    tags: List[str]
    conversation_context: str
    context_images: str
    system_prompt: str
    ai_config: AIConfig

class BotListFile(BaseModel):
    bots: List[Bot]

class ChatMessage(BaseModel):
    role: str # 'user' or 'model'
    text: str

class BotChatRequest(BaseModel):
    bot_id: str
    messages: List[ChatMessage]


# Router
router = APIRouter(prefix="/bots", tags=["bots"])

# ----------------------------------------------------------------------
# ROTAS DE GERENCIAMENTO (EXISTENTES)
# ----------------------------------------------------------------------

@router.post("/", response_model=Bot)
async def create_bot(bot_in: BotIn):
    bot_data = bot_in.model_dump()
    new_bot = Bot(**bot_data)
    MOCK_BOTS_DB[new_bot.id] = new_bot.model_dump()
    return new_bot

@router.get("/", response_model=List[Bot])
async def read_bots():
    # Retorna uma lista de bots a partir do dicion√°rio de mock
    return list(MOCK_BOTS_DB.values())

@router.get("/{bot_id}", response_model=Bot)
async def read_bot(bot_id: str):
    if bot_id not in MOCK_BOTS_DB:
        raise HTTPException(status_code=404, detail="Bot not found")
    return MOCK_BOTS_DB[bot_id]

@router.put("/import", response_model=Dict[str, Any])
async def import_bots(bot_list_file: BotListFile):
    imported_count = 0
    for bot_data in bot_list_file.bots:
        # Se o bot j√° existir, ele ser√° substitu√≠do.
        MOCK_BOTS_DB[bot_data.id] = bot_data.model_dump()
        imported_count += 1
    return {"success": True, "imported_count": imported_count, "message": f"{imported_count} bots imported successfully."}

# ----------------------------------------------------------------------
# NOVA ROTA DE CHAT (CORRE√á√ÉO PARA O ERRO 404)
# ----------------------------------------------------------------------

# NOTE: A rota do frontend √© /groups/send_message. Estamos adicionando-a aqui.
@router.post("/groups/send_message", response_model=Dict[str, str])
async def send_group_message(request: BotChatRequest):
    """
    Simula o envio de uma mensagem para o bot e retorna a resposta do Gemini.
    O endpoint √© /bots/groups/send_message, mas o frontend usa o nome completo.
    """
    bot_id = request.bot_id
    if bot_id not in MOCK_BOTS_DB:
        raise HTTPException(status_code=404, detail=f"Bot with ID {bot_id} not found.")

    bot_data = MOCK_BOTS_DB[bot_id]
    
    # 1. Preparar o contexto para a API Gemini (Simula√ß√£o)
    system_prompt_text = bot_data.get("system_prompt", "Voc√™ √© um assistente √∫til.")
    
    formatted_contents = []
    for msg in request.messages:
        role = "user" if msg.role == "user" else "model"
        formatted_contents.append({
            "role": role,
            "parts": [{"text": msg.text}]
        })

    # 2. Simular a chamada √† API Gemini
    
    bot_name = bot_data['name']
    
    if "pimenta" in bot_name.lower():
        # --- Resposta Dual: Pip (Pimenta) e Professor Cartola (Sarc√°stico) ---
        pip_line = "üå∂Ô∏è O caminho que procuras n√£o tem placas, mas tem cheiro de saudade. Qual labirinto te trouxe aqui?"
        cartola_line = "üé© (Revirando a aba) Mais met√°foras. Excelente. Certifique-se apenas de que o viajante ainda lembra como respirar depois de tanto 'labirinto'."
        ai_response_text = f"{pip_line}\n\n{cartola_line}"
    elif "cartola" in bot_name.lower():
        ai_response_text = "Preocupe-se com o que √© real. Esse questionamento n√£o serve para nada al√©m de ocupar espa√ßo."
    else:
        ai_response_text = f"Ol√°, eu sou {bot_name} e esta √© a minha resposta simulada."
        
    # Adicionamos um pequeno delay para simular o tempo de resposta da IA
    time.sleep(0.5) 

    # 3. Retornar a resposta no formato esperado pelo frontend (texto puro)
    return {"text": ai_response_text}
