import os
import httpx
import time
import logging
from typing import Dict, Any, List

logger = logging.getLogger(__name__)

OPENROUTER_API_BASE_URL = "https://openrouter.ai/api/v1/chat/completions"
MAX_RETRIES = 2
BACKOFF_FACTOR = 1.0

class AIService:
    def __init__(self):
        self.api_key = os.getenv("OPENROUTER_API_KEY")
        self.api_url = OPENROUTER_API_BASE_URL
        
        # Log detalhado da API Key
        if not self.api_key:
            logger.error("âŒ OPENROUTER_API_KEY nÃ£o encontrada nas variÃ¡veis de ambiente!")
            logger.info("ğŸ’¡ No Render: Settings â†’ Environment Variables â†’ OPENROUTER_API_KEY")
        else:
            logger.info(f"âœ… API Key detectada (primeiros 8 chars): {self.api_key[:8]}...")
            logger.info(f"ğŸ“ Comprimento da API Key: {len(self.api_key)} caracteres")

        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "HTTP-Referer": "https://cringe-render.com",
            "X-Title": "CRINGE Bot Platform",
            "Content-Type": "application/json"
        }
        
        # APENAS O MODELO QUE FUNCIONOU: Mistral
        self.available_models = [
            "mistralai/mistral-7b-instruct:free"
        ]
        
        self.current_model_index = 0
        self.http_client = httpx.Client(timeout=30.0)

    def _test_api_connection(self) -> bool:
        """Testa a conexÃ£o com a API OpenRouter usando o modelo Mistral"""
        if not self.api_key:
            logger.error("âŒ Falha no teste: API Key nÃ£o configurada")
            return False
            
        try:
            logger.info("ğŸ§ª Iniciando teste de conexÃ£o com OpenRouter...")
            
            test_payload = {
                "model": self.available_models[0],
                "messages": [{"role": "user", "content": "Responda apenas 'TESTE_OK'"}],
                "max_tokens": 10,
                "temperature": 0.1
            }
            
            logger.info(f"ğŸ”§ Testando modelo: {self.available_models[0]}")
            
            response = self.http_client.post(
                self.api_url,
                headers=self.headers,
                json=test_payload,
                timeout=15
            )
            
            logger.info(f"ğŸ“¡ Status da Resposta: {response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                content = result['choices'][0]['message']['content'].strip()
                logger.info(f"âœ… Teste de conexÃ£o BEM-SUCEDIDO! Resposta: {content}")
                return True
            elif response.status_code == 401:
                logger.error("âŒ ERRO 401: API Key invÃ¡lida ou nÃ£o autorizada")
                return False
            elif response.status_code == 404:
                error_data = response.json()
                model_error = error_data.get('error', {}).get('message', 'Modelo nÃ£o encontrado')
                logger.error(f"âŒ ERRO 404: {model_error}")
                return False
            elif response.status_code == 402:
                logger.error("âŒ ERRO 402: Sem crÃ©ditos ou requisiÃ§Ã£o nÃ£o autorizada")
                return False
            elif response.status_code == 429:
                logger.warning("âš ï¸ ERRO 429: Rate limit excedido")
                return False
            else:
                logger.error(f"âŒ ERRO {response.status_code}: {response.text}")
                return False
                
        except httpx.TimeoutException:
            logger.error("â° Timeout: OpenRouter nÃ£o respondeu em 15 segundos")
            return False
        except httpx.ConnectError:
            logger.error("ğŸ”Œ Erro de conexÃ£o: NÃ£o foi possÃ­vel conectar ao OpenRouter")
            return False
        except Exception as e:
            logger.error(f"ğŸ’¥ Erro inesperado no teste: {str(e)}")
            return False

    def _call_openrouter_api(self, payload: Dict[str, Any]) -> str:
        """Faz chamada para API OpenRouter usando apenas Mistral"""
        
        # VerificaÃ§Ã£o inicial da API Key
        if not self.api_key:
            error_msg = "âŒ **Erro de ConfiguraÃ§Ã£o**: OPENROUTER_API_KEY nÃ£o encontrada."
            logger.error(error_msg)
            return error_msg
        
        # Usar apenas o modelo Mistral
        current_model = self.available_models[0]
        payload["model"] = current_model
        
        logger.info(f"ğŸ”„ Usando modelo: {current_model}")
        
        for attempt in range(MAX_RETRIES):
            try:
                logger.info(f"ğŸ“¤ Tentativa {attempt + 1} para {current_model}")
                
                response = self.http_client.post(
                    self.api_url,
                    headers=self.headers,
                    json=payload,
                    timeout=25.0
                )
                
                logger.info(f"ğŸ“¥ Status: {response.status_code}")
                
                if response.status_code == 200:
                    result = response.json()
                    content = result['choices'][0]['message']['content'].strip()
                    logger.info(f"âœ… Resposta recebida do {current_model}")
                    return content
                
                elif response.status_code == 404:
                    logger.error(f"âŒ Modelo {current_model} nÃ£o encontrado (404)")
                    break
                
                elif response.status_code == 429:
                    wait_time = BACKOFF_FACTOR * (2 ** attempt)
                    logger.warning(f"â° Rate limit, aguardando {wait_time}s...")
                    time.sleep(wait_time)
                    continue
                
                else:
                    logger.warning(f"âš ï¸ Erro {response.status_code} para {current_model}")
                    if attempt < MAX_RETRIES - 1:
                        time.sleep(BACKOFF_FACTOR)
                        continue
            
            except httpx.TimeoutException:
                logger.warning(f"â° Timeout na tentativa {attempt + 1}")
                if attempt < MAX_RETRIES - 1:
                    time.sleep(BACKOFF_FACTOR)
                    continue
            
            except Exception as e:
                logger.error(f"ğŸ’¥ Erro na tentativa {attempt + 1}: {str(e)}")
                if attempt < MAX_RETRIES - 1:
                    time.sleep(BACKOFF_FACTOR)
                    continue
        
        error_msg = "ğŸ”´ **Erro de ConexÃ£o**: NÃ£o foi possÃ­vel conectar ao serviÃ§o de IA. "
        error_msg += "O modelo Mistral pode estar temporariamente indisponÃ­vel."
        logger.error(error_msg)
        return error_msg

    def _prepare_payload(self, system_prompt: str, chat_history: List[Dict[str, str]], user_message: str, temperature: float = 0.7, max_tokens: int = 400) -> Dict[str, Any]:
        """Prepara o payload para a API"""
        messages = []
        
        if system_prompt:
            messages.append({
                "role": "system", 
                "content": system_prompt
            })
        
        # Limitar histÃ³rico para evitar tokens excessivos
        for message in chat_history[-4:]:
            role = message.get("role")
            content = message.get("content", "")
            if role in ["user", "assistant"] and content.strip():
                messages.append({"role": role, "content": content})
        
        messages.append({"role": "user", "content": user_message})
        
        payload = {
            "messages": messages,
            "model": self.available_models[self.current_model_index],
            "temperature": max(0.3, min(temperature, 0.9)),
            "max_tokens": min(max_tokens, 500),
            "stream": False
        }
        
        logger.info(f"ğŸ“ Payload preparado: {len(messages)} mensagens, {max_tokens} tokens")
        return payload

    def generate_response(self, bot_data: Any, ai_config: Dict[str, Any], user_message: str, chat_history: List[Dict[str, str]]) -> str:
        """Gera resposta usando IA"""
        try:
            if hasattr(bot_data, 'to_dict'):
                bot_dict = bot_data.to_dict()
            else:
                bot_dict = bot_data
            
            bot_name = bot_dict.get('name', 'Unknown')
            logger.info(f"ğŸ¤– Gerando resposta para '{bot_name}': {user_message[:50]}...")
            
            temperature = min(ai_config.get('temperature', 0.7), 0.9)
            max_tokens = min(ai_config.get('max_output_tokens', 400), 500)
            
            payload = self._prepare_payload(
                system_prompt=bot_dict['system_prompt'],
                chat_history=chat_history,
                user_message=user_message,
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            response = self._call_openrouter_api(payload)
            
            # Log do resultado
            if response.startswith("âŒ") or response.startswith("ğŸ”´") or response.startswith("ğŸ”Œ"):
                logger.error(f"âŒ Falha na geraÃ§Ã£o de resposta para {bot_name}")
            else:
                logger.info(f"âœ… Resposta gerada com sucesso para {bot_name}")
                
            return response
            
        except Exception as e:
            logger.error(f"ğŸ’¥ Erro crÃ­tico em generate_response: {str(e)}")
            return f"ğŸ”´ **Erro Interno**: {str(e)}"